# 日英翻訳AI（Seq2Seq Transformer）

## 概要

日本語→英語の機械翻訳システム。Transformerアーキテクチャ（Encoder-Decoder）を使用。

**ベース**: `transformer_burn` プロジェクトから派生

## 技術スタック

- **言語**: Rust
- **フレームワーク**: Burn 0.18.0
- **バックエンド**: Wgpu（GPU）、Autodiff（自動微分）
- **アーキテクチャ**: Seq2Seq Transformer（Encoder-Decoder）

## 現在のモデル設定

- **モデル次元**: d_model=16、2ヘッド、d_ff=64
- **層数**: 4層（Encoder/Decoder各4層）
- **シーケンス長**: 10トークン（初期）
- **語彙サイズ**: 未定（日本語 + 英語 + 特殊トークン）

## 開発目標

1. 小規模データセットで動作確認
2. シーケンス長を拡張（20-50トークン）
3. モデルスケールアップ（d_model=64-128）
4. 実用的な翻訳品質を目指す

## 次のステップ

- [ ] 日英対訳データセットの準備
- [ ] 語彙（Vocabulary）の実装
- [ ] データローダーの実装
- [ ] 初回訓練実行
